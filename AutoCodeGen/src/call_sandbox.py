#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified JSONL Processor

ç»Ÿä¸€çš„JSONLå¤„ç†å™¨ï¼Œæ”¯æŒå…¨éƒ¨è¯­è¨€çš„å¤„ç†ã€‚
å¯¹äºgoã€javaã€cppã€javascriptã€pythonè¿™5ä¸ªç‰¹æ®Šè¯­è¨€ï¼Œä½¿ç”¨format_test_codeå¤„ç†åï¼Œå°†å®Œæ•´ä»£ç ä½œä¸ºsource_codeä¼ ç»™submitæ¥å£ã€‚
å¯¹äºå…¶ä»–è¯­è¨€ï¼Œä½¿ç”¨ä¼ ç»Ÿçš„func_codeå’Œmain_codeæ–¹å¼ã€‚
"""

import json
import requests
import time
import argparse
import os
import logging
import re
import uuid
from typing import Dict, Any, List, Set
from multiprocessing import Pool, Manager, Queue
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm
from prettytable import PrettyTable

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('unified_processor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å…¨å±€å¤„ç†å™¨å®ä¾‹ï¼Œé¿å…é‡å¤åˆ›å»º
_global_processor = None


def init_worker(server_ip, server_port):
    """åˆå§‹åŒ–å·¥ä½œè¿›ç¨‹"""
    global _global_processor
    _global_processor = UnifiedProcessor(server_ip, server_port)


def process_single_data_worker(args):
    """å¤šè¿›ç¨‹å·¥ä½œå‡½æ•°ï¼Œå¤„ç†å•æ¡æ•°æ®"""
    data, index, debug = args
    global _global_processor

    # ä½¿ç”¨å…¨å±€å¤„ç†å™¨å®ä¾‹
    result = _global_processor.process_data(data, debug)
    result["index"] = index
    result["original_data"] = data

    return result


def process_single_data_worker(data, index, debug, print_code=False):
    """å•ä»»åŠ¡å·¥ä½œå‡½æ•°ï¼Œå¤„ç†ä¸€æ¡æ•°æ®"""
    global _global_processor

    result = _global_processor.process_data(data, debug, print_code)
    result["index"] = index
    result["original_data"] = data

    time.sleep(0.2)  # é€‚å½“å»¶è¿Ÿé¿å…APIè¿‡è½½
    return result


class UnifiedProcessor:
    def __init__(self, server_ip: str = "21.86.44.177", server_port: int = 8080):
        self.server_ip = server_ip
        self.server_port = server_port
        self.submit_url = f"http://{server_ip}:{server_port}/submit"
        self.headers = {
            "Content-Type": "application/json"
        }
        # éœ€è¦ç‰¹æ®Šå¤„ç†çš„è¯­è¨€ï¼ˆä½¿ç”¨format_test_codeï¼‰
        self.special_languages = ["go", "java", "cpp", "javascript", "python"]
        # self.special_languages = []

    def format_test_code(self, language: str, main_code: str, test_code: str, is_demo_test: bool = True) -> str:
        """ä½¿ç”¨format_test_codeé€»è¾‘å¤„ç†ç‰¹æ®Šè¯­è¨€çš„ä»£ç .ä½¿ç”¨æ²™ç›’æ‰§è¡Œå¾—åˆ°test outputè¦è°ƒç”¨æ­¤é€»è¾‘ã€‚å› ä¸ºæ­¤é€»è¾‘å’Œbenchè¯„æµ‹æ—¶é€»è¾‘ä¸ä¸€è‡´ã€‚"""
        if language == "javascript":
            if is_demo_test:
                code_req = main_code + "\n" + test_code + "\n\ndemoTesting()"
            else:
                code_req = main_code + "\n" + test_code + "\n\nfullTesting()"
        elif language == "go":
            import_info = self._go_extract_and_merge_imports([main_code, test_code])
            main_code = re.sub(r'import\s*(?:\(.*?\)|"[^"]+")\s*', '', main_code, flags=re.DOTALL)
            main_code = main_code.replace("package main", "")
            main_code = "package main\n" + import_info + "\n" + main_code
            test_code = re.sub(r'import\s*(?:\(.*?\)|"[^"]+")\s*', '', test_code, flags=re.DOTALL)
            test_code = test_code.replace("package main", "")
            if re.search(r'\s*func\s+Test\w+.+', test_code):
                go_test_method = "test"
            else:
                go_test_method = "main"
            if go_test_method == "main":
                main_func = "func main() {demoTesting()}" if is_demo_test else "func main() {fullTesting()}"
            else:
                main_func = ""
            code_req = main_code + "\n" + test_code + "\n\n" + main_func
            # åˆ é™¤æœªä½¿ç”¨åˆ°çš„importåŒ…
            code_req = self._go_remove_unused_imports(code_req)
        elif language == "cpp":
            model_func = main_code.strip().split("int main")[0]
            code_req = model_func + "\n" + test_code
            code_req = "#include <iostream>\nusing namespace std;\n" + code_req
        elif language == "java":
            # å°†ä¸»å‡½æ•°ä¸­çš„public classï¼Œprivate class å’Œ protected classéƒ½è½¬æˆclassã€‚
            main_code = main_code.replace("public class", "class").replace("private class", "class").replace("protected class", "class")

            # test code
            test_code = test_code.replace("public class", "class").replace("private class", "class").replace("protected class", "class")
            # æå–ç”¨åˆ°çš„åŒ…
            answer_packages = [line for line in main_code.split('\n') if line.startswith("import ")]
            # å°†packageå¼€å¤´çš„è¡Œä»¥åŠå¯¼å…¥åŒ…çš„è¡Œå»é™¤
            answer_code = [line for line in main_code.split('\n') if not (line.startswith("import ") or line.startswith("package "))]
            answer_code = "\n".join(answer_code)
            # æå–æµ‹è¯•å‡½æ•°çš„ç”¨åˆ°çš„åŒ…
            test_packages = [line for line in test_code.split('\n') if line.startswith("import ")]
            # å¯¹å¯¼å…¥çš„åŒ…å»é‡
            all_packages = answer_packages + test_packages
            all_packages = list(set(all_packages))
            all_packages = "\n".join(all_packages)
            # å°†packageå¼€å¤´çš„è¡Œä»¥åŠå¯¼å…¥åŒ…çš„è¡Œå»é™¤
            test_code = [line for line in test_code.split('\n') if not (line.startswith("import ") or line.startswith("package "))]
            test_code = "\n".join(test_code)
            # æ‹¼æ¥
            code_req = all_packages + "\n" + answer_code + "\n" + test_code
        elif language == "python":
            code_req = main_code + "\n" + test_code
        else:
            raise Exception(f"ä¸æ”¯æŒçš„è¯­è¨€ç±»å‹ï¼š{language}")
        return code_req
    
    def _go_extract_and_merge_imports(self, code_blocks: list):
        """æå–å¹¶åˆå¹¶Goä»£ç ä¸­çš„importè¯­å¥"""
        imports = set()
        for code in code_blocks:
            # åŒ¹é…å¸¦æ‹¬å·çš„å¤šè¡Œimportå’Œå•è¡Œimport
            matches = re.findall(r'import\s*(?:\((.*?)\)|"([^"]+)")', code, re.DOTALL)
            for match in matches:
                # å¤„ç†ä¸¤ç§åŒ¹é…ç»“æœ
                for imp in match:
                    if imp.strip():
                        # åˆ†å‰²å¤šè¡Œimportä¸­çš„å„ä¸ªåŒ…
                        for line in imp.split('\n'):
                            line = line.strip()
                            if line and not line.startswith('//'):  # å¿½ç•¥æ³¨é‡Š
                                # å»é™¤å¯èƒ½çš„å¼•å·å’Œåˆ†å·
                                line = line.replace('"', '').replace(';', '').strip()
                                if line:
                                    imports.add(line)

        # ç”Ÿæˆåˆå¹¶åçš„importè¯­å¥
        if imports:
            merged_import = "import (\n"
            for imp in imports:
                merged_import += f'    "{imp}"\n'
            merged_import += ")"
        else:
            merged_import = ""

        return merged_import

    def _go_remove_unused_imports(self, go_code: str) -> str:
        """ç§»é™¤Goä»£ç ä¸­æœªä½¿ç”¨çš„importåŒ…"""
        # 1. æ‰¾å‡ºæ‰€æœ‰importè¯­å¥ï¼ˆåŒ…æ‹¬åˆ†ç»„å’Œç‹¬ç«‹importï¼‰
        imports = []

        # å¤„ç†åˆ†ç»„import (import (...))
        for match in re.finditer(r'import\s*\(([\s\S]*?)\)', go_code):
            imports.append(('grouped', match.start(), match.end(), match.group(1)))

        # å¤„ç†ç‹¬ç«‹import (import "pkg")
        for match in re.finditer(r'import\s+"([^"]+)"', go_code):
            imports.append(('single', match.start(), match.end(), match.group(1)))

        # å¦‚æœæ²¡æœ‰importè¯­å¥ï¼Œç›´æ¥è¿”å›
        if not imports:
            return go_code

        # 2. æ”¶é›†æ‰€æœ‰å¯¼å…¥çš„åŒ…
        imported_pkgs = set()
        for imp_type, start, end, content in imports:
            if imp_type == 'grouped':
                # ä»åˆ†ç»„ä¸­æå–æ‰€æœ‰åŒ…
                imported_pkgs.update(re.findall(r'"([^"]+)"', content))
            else:  # single
                imported_pkgs.add(content)

        # 3. æ‰¾å‡ºå®é™…ä½¿ç”¨çš„åŒ…
        used_pkgs: Set[str] = set()
        for pkg in imported_pkgs:
            pkg_identifier = pkg.split('/')[-1]
            # æ’é™¤importéƒ¨åˆ†æ£€æŸ¥ä½¿ç”¨æƒ…å†µ
            code_without_imports = go_code
            for _, start, end, _ in imports:
                code_without_imports = code_without_imports[:start] + ' ' * (end - start) + code_without_imports[end:]
            pkg_identifier = re.escape(pkg_identifier)
            if re.search(rf'(?<!\w){pkg_identifier}(?!\w)', code_without_imports):
                used_pkgs.add(pkg)

        # 4. é‡å»ºä»£ç 
        result = []
        last_pos = 0

        for imp_type, start, end, content in sorted(imports, key=lambda x: x[1]):
            # æ·»åŠ importä¹‹å‰çš„ä»£ç 
            result.append(go_code[last_pos:start])

            if imp_type == 'grouped':
                # å¤„ç†åˆ†ç»„import
                new_lines = []
                for line in content.split('\n'):
                    line = line.strip()
                    if not line:
                        new_lines.append('')
                        continue
                    pkg = re.search(r'"([^"]+)"', line)
                    if pkg and pkg.group(1) in used_pkgs:
                        new_lines.append(line)

                if new_lines:
                    result.append(f'import (\n' + '\n'.join(new_lines) + '\n)')
            else:  # single
                # å¤„ç†ç‹¬ç«‹import
                if content in used_pkgs:
                    result.append(f'import "{content}"')

            last_pos = end

        # æ·»åŠ æœ€åéƒ¨åˆ†ä»£ç 
        result.append(go_code[last_pos:])

        return ''.join(result)
 
    def read_jsonl_file(self, file_path: str, line_number: int = None, target_language: str = None) -> List[Dict[str, Any]]:
        """è¯»å–JSONLæ–‡ä»¶å¹¶è¿”å›æ•°æ®åˆ—è¡¨"""
        data_list = []
        total_count = 0
        filtered_count = 0

        try:
            # å¦‚æœæŒ‡å®šäº†è¡Œå·ï¼Œéœ€è¦ä¸¤éå¤„ç†ï¼šç¬¬ä¸€éç»Ÿè®¡ï¼Œç¬¬äºŒéé€‰æ‹©
            if line_number is not None:
                # ç¬¬ä¸€éï¼šç»Ÿè®¡æ€»æ•°æ®å’ŒåŒ¹é…æ•°æ®
                with open(file_path, 'r', encoding='utf-8') as file:
                    for line_num, line in enumerate(file, 1):
                        line = line.strip()
                        if line:
                            try:
                                data = json.loads(line)
                                total_count += 1

                                # è¯­è¨€è¿‡æ»¤ç»Ÿè®¡
                                if target_language:
                                    data_language = data.get("language", "").lower()
                                    if data_language == target_language.lower():
                                        filtered_count += 1
                                else:
                                    filtered_count += 1
                            except json.JSONDecodeError as e:
                                logger.error(f"ç¬¬{line_num}è¡ŒJSONè§£æé”™è¯¯: {e}")
                                continue

                # ç¬¬äºŒéï¼šé€‰æ‹©æŒ‡å®šè¡Œå·çš„æ•°æ®
                current_filtered = 0
                with open(file_path, 'r', encoding='utf-8') as file:
                    for line_num, line in enumerate(file, 1):
                        line = line.strip()
                        if line:
                            try:
                                data = json.loads(line)

                                # è¯­è¨€è¿‡æ»¤
                                if target_language:
                                    data_language = data.get("language", "").lower()
                                    if data_language != target_language.lower():
                                        continue

                                current_filtered += 1
                                if current_filtered == line_number:
                                    # æ·»åŠ ç»å¯¹è¡Œå·ä¿¡æ¯
                                    data['_absolute_line_number'] = line_num
                                    data['_relative_line_number'] = current_filtered
                                    data_list.append(data)
                                    break
                            except json.JSONDecodeError as e:
                                continue
            else:
                # æ²¡æœ‰æŒ‡å®šè¡Œå·ï¼Œä¸€éå¤„ç†å³å¯
                with open(file_path, 'r', encoding='utf-8') as file:
                    for line_num, line in enumerate(file, 1):
                        line = line.strip()
                        if line:
                            try:
                                data = json.loads(line)

                                total_count += 1

                                # è¯­è¨€è¿‡æ»¤
                                if target_language:
                                    data_language = data.get("language", "").lower()
                                    if data_language != target_language.lower():
                                        continue
                                    filtered_count += 1
                                else:
                                    filtered_count += 1

                                # æ·»åŠ ç»å¯¹è¡Œå·å’Œç›¸å¯¹è¡Œå·ä¿¡æ¯
                                data['_absolute_line_number'] = line_num
                                data['_relative_line_number'] = filtered_count
                                data_list.append(data)
                            except json.JSONDecodeError as e:
                                logger.error(f"ç¬¬{line_num}è¡ŒJSONè§£æé”™è¯¯: {e}")
                                continue

            if target_language:
                logger.info(f"è¯­è¨€è¿‡æ»¤: {target_language} - æ€»æ•°æ®{total_count}æ¡ï¼ŒåŒ¹é…{filtered_count}æ¡ï¼Œæœ€ç»ˆè¯»å–{len(data_list)}æ¡")
            else:
                logger.info(f"æˆåŠŸè¯»å–{len(data_list)}æ¡æ•°æ®")
            return data_list
        except FileNotFoundError:
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return []
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []


    def extract_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æå–éœ€è¦çš„å­—æ®µ"""
        return {
            "language": data.get("language", "").lower(),
            "full_test_func": data.get("full_test_func", ""),
            "demo_test_func": data.get("demo_test_func", ""),
            "main_test_func": data.get("extracted_code", "")
        }
    
    def call_submit_api(self, data: Dict[str, Any], test_type: str = "full", debug: bool = False, print_code: bool = False) -> Dict[str, Any]:
        """è°ƒç”¨submitæ¥å£"""
        try:
            language = data["language"]
            is_special_language = language in self.special_languages
            
            # æ ¹æ®æµ‹è¯•ç±»å‹é€‰æ‹©æµ‹è¯•ä»£ç 
            if test_type == "full":
                test_code = data["full_test_func"]
            elif test_type == "demo":
                test_code = data["demo_test_func"]
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æµ‹è¯•ç±»å‹: {test_type}")
            
            if is_special_language:
                # ç‰¹æ®Šè¯­è¨€ï¼šä½¿ç”¨format_test_codeå¤„ç†ï¼Œå°†å®Œæ•´ä»£ç ä½œä¸ºsource_code
                is_demo_test = (test_type == "demo")
                formatted_code = self.format_test_code(
                    language, 
                    data["main_test_func"], 
                    test_code, 
                    is_demo_test
                )
                
                # åœ¨æŒ‡å®šè¡Œæ¨¡å¼ä¸‹æ‰“å°formatted_code
                if print_code:
                    print(f"\n{'='*80}")
                    print(f"ğŸ” {test_type.upper()} æµ‹è¯• - {language.upper()} æ ¼å¼åŒ–ä»£ç :")
                    print(f"{'='*80}")
                    print(formatted_code)
                    print(f"{'='*80}\n")

                # import pdb
                # pdb.set_trace()

                # ç¡®å®šGoæµ‹è¯•æ–¹æ³•
                # if language == "go" and re.search(r'\s*func\s+Test\w+.+', test_code):
                if language == 'go' and "(t *testing.T)" in test_code:
                    go_test_method = "test"
                else:
                    go_test_method = "main"
                
                payload = {
                    "src_uid": str(uuid.uuid4()),
                    "sandbox_type": "General",
                    "source_code": formatted_code,  # ä½¿ç”¨æ ¼å¼åŒ–åçš„å®Œæ•´ä»£ç 
                    "lang": language,
                    "show_log": True,
                    "request_extensions": {
                        "timeout": 30.0,
                        "debug": str(debug).lower(),
                        "go_test_method": go_test_method,
                        "target": "test",
                    }
                }
            else:
                # æ™®é€šè¯­è¨€ï¼šä½¿ç”¨ä¼ ç»Ÿçš„func_codeå’Œmain_codeæ–¹å¼
                payload = {
                    "src_uid": f"0710_bench_test_{test_type}_{int(time.time())}",
                    "func_code": data["main_test_func"],
                    "main_code": test_code,
                    "lang": language,
                    "show_log": "true",
                    "request_extensions": {"timeout": 30, "debug": str(debug).lower()}
                }
            
            # logger.info(f"è°ƒç”¨submitæ¥å£ï¼Œæµ‹è¯•ç±»å‹: {test_type}, è¯­è¨€: {language}, ç‰¹æ®Šå¤„ç†: {is_special_language}, debug: {debug}")
            response = requests.post(self.submit_url, headers=self.headers, json=payload, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                # logger.info(f"APIè°ƒç”¨æˆåŠŸï¼Œ{test_type}ï¼Œç»“æœ: {result.get('exec_outcome', 'unknown')}")
                return {
                    "success": True,
                    "response": result,
                    "status_code": response.status_code
                }
            else:
                logger.error(f"APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}: {response.text}",
                    "status_code": response.status_code
                }
                
        except requests.exceptions.Timeout:
            logger.error("APIè°ƒç”¨è¶…æ—¶")
            return {
                "success": False,
                "error": "è¯·æ±‚è¶…æ—¶",
                "status_code": None
            }
        except requests.exceptions.RequestException as e:
            logger.error(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": str(e),
                "status_code": None
            }
        except Exception as e:
            logger.error(f"å¤„ç†æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {
                "success": False,
                "error": str(e),
                "status_code": None
            }
    
    def process_data(self, data: Dict[str, Any], debug: bool = False, print_code: bool = False) -> Dict[str, Any]:
        """å¤„ç†å•æ¡æ•°æ®ï¼Œè°ƒç”¨ä¸¤æ¬¡submitæ¥å£"""
        extracted_data = self.extract_fields(data)
        
        # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
        if not all(extracted_data.values()):
            logger.warning("æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µï¼Œè·³è¿‡å¤„ç†")
            return {
                "success": False,
                "error": "ç¼ºå°‘å¿…è¦å­—æ®µ",
                "full_test_result": None,
                "demo_test_result": None,
                "language": extracted_data["language"]
            }
        
        # è°ƒç”¨full_test_func
        full_test_result = self.call_submit_api(extracted_data, "full", debug, print_code)

        # ç­‰å¾…ä¸€ç§’å†è°ƒç”¨demo_test_func
        time.sleep(1)
        
        # è°ƒç”¨demo_test_func
        demo_test_result = self.call_submit_api(extracted_data, "demo", debug, print_code)

        # åˆ¤æ–­æ•´ä½“æ˜¯å¦æˆåŠŸï¼ˆä¸¤ä¸ªAPIè°ƒç”¨éƒ½æˆåŠŸä¸”ä»£ç æ‰§è¡Œéƒ½é€šè¿‡æ‰ç®—æˆåŠŸï¼‰
        full_api_success = full_test_result.get("success", False)
        demo_api_success = demo_test_result.get("success", False)
        
        # æ£€æŸ¥ä»£ç æ‰§è¡Œç»“æœ
        full_exec_passed = (full_api_success and 
                           full_test_result.get("response", {}).get("exec_outcome") == "PASSED")
        demo_exec_passed = (demo_api_success and 
                           demo_test_result.get("response", {}).get("exec_outcome") == "PASSED")
        
        # æ•´ä½“æˆåŠŸï¼šä¸¤ä¸ªAPIè°ƒç”¨éƒ½æˆåŠŸä¸”ä»£ç æ‰§è¡Œéƒ½é€šè¿‡
        overall_success = full_exec_passed and demo_exec_passed
        
        # åœ¨æŒ‡å®šè¡Œæ¨¡å¼ä¸‹ï¼Œå¦‚æœæµ‹è¯•å¤±è´¥ï¼Œæ‰“å°å®Œæ•´çš„responseä¿¡æ¯
        if print_code and not overall_success:
            print(f"\n{'='*80}")
            print(f"âŒ æµ‹è¯•å¤±è´¥è¯¦æƒ… - {extracted_data['language'].upper()}")
            print(f"{'='*80}")

            # æ‰“å°FULLæµ‹è¯•ç»“æœ
            print(f"\nğŸ” FULL æµ‹è¯•ç»“æœ:")
            print(f"   APIè°ƒç”¨æˆåŠŸ: {full_api_success}")
            print(f"   æ‰§è¡Œç»“æœ: {full_test_result.get('response', {}).get('exec_outcome', 'unknown')}")
            if full_test_result.get("response"):
                print(f"   å®Œæ•´å“åº”:")
                print(json.dumps(full_test_result["response"], indent=2, ensure_ascii=False))
            elif full_test_result.get("error"):
                print(f"   é”™è¯¯ä¿¡æ¯: {full_test_result['error']}")

            # æ‰“å°DEMOæµ‹è¯•ç»“æœ
            print(f"\nğŸ” DEMO æµ‹è¯•ç»“æœ:")
            print(f"   APIè°ƒç”¨æˆåŠŸ: {demo_api_success}")
            print(f"   æ‰§è¡Œç»“æœ: {demo_test_result.get('response', {}).get('exec_outcome', 'unknown')}")
            if demo_test_result.get("response"):
                print(f"   å®Œæ•´å“åº”:")
                print(json.dumps(demo_test_result["response"], indent=2, ensure_ascii=False))
            elif demo_test_result.get("error"):
                print(f"   é”™è¯¯ä¿¡æ¯: {demo_test_result['error']}")

            print(f"{'='*80}\n")

        return {
            "success": overall_success,
            "full_test_result": full_test_result,
            "demo_test_result": demo_test_result,
            "language": extracted_data["language"],
            "full_test_detail": full_test_result.get("response", {}),
            "demo_test_detail": demo_test_result.get("response", {})
        }
    
    def process_file(self, file_path: str, max_items: int = None, line_number: int = None,
                     debug: bool = False, concurrency: int = 5, target_language: str = None,
                     solution_key: str = 'output') -> List[Dict[str, Any]]:
        """å¤„ç†æ•´ä¸ªJSONLæ–‡ä»¶"""
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")
        if target_language:
            logger.info(f"è¯­è¨€è¿‡æ»¤: åªå¤„ç† {target_language} è¯­è¨€çš„æ•°æ®")

        # è¯»å–æ•°æ®
        data_list = self.read_jsonl_file(file_path, line_number, target_language)
        if not data_list:
            return []
        def _extract_code_blocks(language, model_answer):
            """
            æŠ½å–ä»£ç å—
            """
            extract_code = ""
            if language == "python":
                #pattern = rf"```python(.*?)```"
                pattern = r'```.*?\n(.*?)```'
                matches = re.findall(pattern, model_answer, re.DOTALL)
                blocks = [match.strip() for match in matches]
                
                max_code, max_len = None, -1
                for bl in blocks:
                    lens = len(bl.split("\n"))
                    if lens > max_len:
                        max_code, max_len = bl, lens
                if max_code and max_code != "":
                    extract_code = max_code
            else:
                #pattern_str = rf"```(bash|shell|sh)(.*?)```" if self.language in ["shell", "bash"] else rf'```({self.language})(.*?)```'
                pattern_str = r'```(.*?)\n(.*?)```'
                pattern = re.compile(pattern_str, re.DOTALL)
                code_blocks = pattern.findall(model_answer)
                if len(code_blocks) > 0:
                    extract_code = code_blocks[0][1].strip()
            return extract_code

        for data in data_list:
            extract_code = _extract_code_blocks(data["language"], data[solution_key])
            data["extracted_code"] = extract_code if extract_code else "no code extracted"

        # é™åˆ¶å¤„ç†æ•°é‡ï¼ˆåªæœ‰åœ¨æ²¡æœ‰æŒ‡å®šè¡Œå·æ—¶æ‰ç”Ÿæ•ˆï¼‰
        if max_items and line_number is None:
            data_list = data_list[:max_items]
            logger.info(f"é™åˆ¶å¤„ç†æ•°é‡ä¸º: {max_items}")
        
        # å¦‚æœåªæœ‰ä¸€æ¡æ•°æ®æˆ–æŒ‡å®šäº†è¡Œå·ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†
        if len(data_list) == 1 or line_number is not None:
            logger.info("ä½¿ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼")
            return self._process_file_serial(data_list, line_number, debug)

        # ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†
        logger.info(f"ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†æ¨¡å¼ï¼Œå¹¶å‘æ•°: {concurrency}")
        return self._process_file_multiprocess(data_list, debug, concurrency)

    def _process_file_serial(self, data_list: List[Dict[str, Any]], line_number: int = None,
                           debug: bool = False) -> List[Dict[str, Any]]:
        """ä¸²è¡Œå¤„ç†æ–‡ä»¶"""
        results = []

        # åˆ¤æ–­æ˜¯å¦ä¸ºæŒ‡å®šè¡Œæ¨¡å¼ï¼ˆç”¨äºæ‰“å°ä»£ç ï¼‰
        is_single_line_mode = line_number is not None

        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
        desc = f"å¤„ç†ç¬¬{line_number}è¡Œæ•°æ®" if line_number else "ä¸²è¡Œå¤„ç†"
        with tqdm(total=len(data_list), desc=desc, unit="æ¡") as pbar:
            for i, data in enumerate(data_list, 1):
                result = self.process_data(data, debug, print_code=is_single_line_mode)
                result["index"] = i
                result["original_data"] = data
                results.append(result)

                # æ›´æ–°è¿›åº¦æ¡
                pbar.update(1)
                pbar.set_postfix({
                    "æˆåŠŸ": sum(1 for r in results if r.get("success", False)),
                    "å¤±è´¥": sum(1 for r in results if not r.get("success", False))
                })

                # åœ¨æ¯æ¬¡å¤„ç†ä¹‹é—´ç¨ä½œç­‰å¾…ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                if i < len(data_list):
                    time.sleep(0.5)

        logger.info(f"ä¸²è¡Œå¤„ç†å®Œæˆï¼Œå…±å¤„ç†{len(results)}æ¡æ•°æ®")
        return results
    
    def _process_file_multiprocess(self, data_list: List[Dict[str, Any]], debug: bool = False,
                                 concurrency: int = 5) -> List[Dict[str, Any]]:
        """å¤šè¿›ç¨‹å¤„ç†æ–‡ä»¶ - ç®€åŒ–ç‰ˆæœ¬"""
        total_items = len(data_list)

        # å¦‚æœæ•°æ®é‡å°ï¼Œç›´æ¥ä½¿ç”¨ä¸²è¡Œå¤„ç†
        if total_items < concurrency:
            logger.info(f"æ•°æ®é‡è¾ƒå°({total_items}æ¡)ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†")
            return self._process_file_serial(data_list, debug=debug)

        logger.info(f"å¯åŠ¨{concurrency}ä¸ªè¿›ç¨‹å¤„ç†{total_items}æ¡æ•°æ®")

        results = []
        try:
            # ä½¿ç”¨è¿›ç¨‹æ± ï¼Œæ¯ä¸ªä»»åŠ¡å¤„ç†ä¸€æ¡æ•°æ®
            with Pool(processes=concurrency, initializer=init_worker, initargs=(self.server_ip, self.server_port)) as pool:
                # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
                with tqdm(total=total_items, desc=f"å¤šè¿›ç¨‹å¤„ç†({concurrency}è¿›ç¨‹)", unit="æ¡") as pbar:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    futures = []
                    for i, data in enumerate(data_list, 1):
                        future = pool.apply_async(process_single_data_worker, (data, i, debug, False))
                        futures.append(future)

                    # æ”¶é›†ç»“æœ
                    for future in futures:
                        try:
                            result = future.get(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                            results.append(result)
                            pbar.update(1)

                            # æ›´æ–°è¿›åº¦æ¡ç»Ÿè®¡
                            pbar.set_postfix({
                                "æˆåŠŸ": sum(1 for r in results if r.get("success", False)),
                                "å¤±è´¥": sum(1 for r in results if not r.get("success", False))
                            })
                        except Exception as e:
                            logger.error(f"ä»»åŠ¡å¤±è´¥: {e}")
                            # åˆ›å»ºå¤±è´¥ç»“æœ
                            failed_result = {
                                "index": len(results) + 1,
                                "success": False,
                                "error": str(e),
                                "original_data": {}
                            }
                            results.append(failed_result)
                            pbar.update(1)

        except Exception as e:
            logger.error(f"å¤šè¿›ç¨‹å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            # å¦‚æœå¤šè¿›ç¨‹å¤±è´¥ï¼Œå›é€€åˆ°ä¸²è¡Œå¤„ç†
            logger.info("å›é€€åˆ°ä¸²è¡Œå¤„ç†æ¨¡å¼")
            return self._process_file_serial(data_list, debug=debug)

        # æŒ‰indexæ’åºç»“æœ
        results.sort(key=lambda x: x.get("index", 0))

        logger.info(f"å¤šè¿›ç¨‹å¤„ç†å®Œæˆï¼Œå…±å¤„ç†{len(results)}æ¡æ•°æ®")
        return results

    def save_results(self, results: List[Dict[str, Any]], output_file: str):
        """ä¿å­˜å¤„ç†ç»“æœåˆ°æ–‡ä»¶"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                for result in results:
                    # ç®€åŒ–è¾“å‡ºæ ¼å¼ï¼Œåªä¿ç•™å¿…è¦ä¿¡æ¯
                    simplified_result = {
                        "index": result.get("index", 0),
                        "language": result.get("language", ""),
                        "success": result.get("success", False),
                        # "full_test_outcome": result.get("full_test_result", {}).get("response", {}).get("exec_outcome", "unknown"),
                        # "demo_test_outcome": result.get("demo_test_result", {}).get("response", {}).get("exec_outcome", "unknown"),
                        "full_test_result": result.get("full_test_result", {}),
                        "demo_test_result": result.get("demo_test_result", {}),
                        # "full_test_output": result.get("full_test_result", {}).get("response", {}).get("exec_cout", ""),
                        # "demo_test_output": result.get("demo_test_result", {}).get("response", {}).get("exec_cout", ""),
                        # "full_test_error": result.get("full_test_result", {}).get("error", ""),
                        # "demo_test_error": result.get("demo_test_result", {}).get("error", ""),
                        "original_data": result.get("original_data", {})
                    }
                    f.write(json.dumps(simplified_result, ensure_ascii=False) + '\n')
            logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}")

    def print_detailed_statistics(self, results: List[Dict[str, Any]]):
        """æ‰“å°è¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Šè¡¨æ ¼"""
        if not results:
            print("\nâŒ æ²¡æœ‰å¤„ç†ä»»ä½•æ•°æ®")
            return

        # æŒ‰è¯­è¨€åˆ†ç»„ç»Ÿè®¡
        language_stats = {}
        failed_items = []

        for result in results:
            try:
                language = result.get("language", "unknown")
                success = result.get("success", False)
                index = result.get("index", 0)

                # åˆå§‹åŒ–è¯­è¨€ç»Ÿè®¡
                if language not in language_stats:
                    language_stats[language] = {
                        "total": 0,
                        "success": 0,
                        "failed": 0,
                        "full_passed": 0,
                        "demo_passed": 0,
                        "both_passed": 0,
                        "failed_indices": []
                    }

                # æ›´æ–°ç»Ÿè®¡
                stats = language_stats[language]
                stats["total"] += 1

                if success:
                    stats["success"] += 1
                else:
                    stats["failed"] += 1
                    # è·å–ç»å¯¹è¡Œå·å’Œç›¸å¯¹è¡Œå·
                    absolute_line = result.get("original_data", {}).get("_absolute_line_number", index)
                    relative_line = result.get("original_data", {}).get("_relative_line_number", index)

                    stats["failed_indices"].append({
                        "absolute_line": absolute_line,
                        "relative_line": relative_line
                    })
                    failed_items.append({
                        "index": index,
                        "absolute_line": absolute_line,
                        "relative_line": relative_line,
                        "language": language,
                        "full_outcome": result.get("full_test_result", {}).get("response", {}).get("exec_outcome", "unknown"),
                        "demo_outcome": result.get("demo_test_result", {}).get("response", {}).get("exec_outcome", "unknown"),
                        "full_error": result.get("full_test_result", {}).get("error", ""),
                        "demo_error": result.get("demo_test_result", {}).get("error", "")
                    })

                # è¯¦ç»†æµ‹è¯•ç»“æœç»Ÿè®¡
                full_outcome = result.get("full_test_result", {}).get("response", {}).get("exec_outcome", "")
                demo_outcome = result.get("demo_test_result", {}).get("response", {}).get("exec_outcome", "")

                if full_outcome == "PASSED":
                    stats["full_passed"] += 1
                if demo_outcome == "PASSED":
                    stats["demo_passed"] += 1
                if full_outcome == "PASSED" and demo_outcome == "PASSED":
                    stats["both_passed"] += 1
            except Exception as e:
                logger.error(f"æµ‹è¯•ç»Ÿè®¡ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e} æ•°æ®:\n {result}")
                continue

        # æ‰“å°æ€»ä½“ç»Ÿè®¡
        total_items = len(results)
        total_success = sum(1 for r in results if r.get("success", False))
        total_failed = total_items - total_success

        print("\n" + "="*80)
        print("ğŸ¯ æ‰§è¡Œç»“æœç»Ÿè®¡æŠ¥å‘Š")
        print("="*80)

        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»å¤„ç†æ•°æ®: {total_items} æ¡")
        print(f"   æˆåŠŸæ•°æ®:   {total_success} æ¡ ({total_success/total_items*100:.1f}%)")
        print(f"   å¤±è´¥æ•°æ®:   {total_failed} æ¡ ({total_failed/total_items*100:.1f}%)")

        # ä½¿ç”¨ PrettyTable æ‰“å°å„è¯­è¨€è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼
        print(f"\nğŸ“‹ å„è¯­è¨€è¯¦ç»†ç»Ÿè®¡:")
        language_table = PrettyTable()
        language_table.field_names = ["è¯­è¨€", "æ€»æ•°", "æˆåŠŸ", "å¤±è´¥", "æˆåŠŸç‡", "Demoé€šè¿‡", "Fullé€šè¿‡", "åŒé€šè¿‡"]
        language_table.align = "l"
        language_table.align["æ€»æ•°"] = "r"
        language_table.align["æˆåŠŸ"] = "r"
        language_table.align["å¤±è´¥"] = "r"
        language_table.align["æˆåŠŸç‡"] = "r"
        language_table.align["Demoé€šè¿‡"] = "r"
        language_table.align["Fullé€šè¿‡"] = "r"
        language_table.align["åŒé€šè¿‡"] = "r"

        # æŒ‰è¯­è¨€åç§°æ’åºæ·»åŠ æ•°æ®
        for language in sorted(language_stats.keys()):
            stats = language_stats[language]
            success_rate = stats["success"] / stats["total"] * 100 if stats["total"] > 0 else 0

            language_table.add_row([
                language,
                stats["total"],
                stats["success"],
                stats["failed"],
                f"{success_rate:.1f}%",
                stats["demo_passed"],
                stats["full_passed"],
                stats["both_passed"]
            ])

        print(language_table)

        
def main():
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€JSONLæ–‡ä»¶å¤„ç†å™¨ï¼ˆæ”¯æŒå…¨éƒ¨è¯­è¨€ï¼‰')
    parser.add_argument('-i', '--input_file', help='è¾“å…¥çš„JSONLæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-m', '--max-items', type=int, help='æœ€å¤§å¤„ç†æ•°é‡')
    parser.add_argument('-l', '--line', type=int, help='æŒ‡å®šå¤„ç†ç¬¬å‡ è¡Œæ•°æ®ï¼ˆä»1å¼€å§‹ï¼‰')
    parser.add_argument('--server_ip', help='æœåŠ¡å™¨IPåœ°å€', default='21.86.44.177')
    parser.add_argument('--server_port', type=int, help='æœåŠ¡å™¨ç«¯å£', default=8080)
    parser.add_argument('-d', '--debug', action='store_true', help='å¯ç”¨debugæ¨¡å¼')
    parser.add_argument('-c', '--concurrency', type=int, default=30, help='å¹¶å‘è¿›ç¨‹æ•°ï¼ˆé»˜è®¤30ï¼‰')
    parser.add_argument('--lang', help='æŒ‡å®šå¤„ç†çš„ç¼–ç¨‹è¯­è¨€ï¼Œåªå¤„ç†è¯¥è¯­è¨€çš„æ•°æ®')
    parser.add_argument('--solution_key', default='output', help='æŒ‡å®šè§£å†³æ–¹æ¡ˆæ‰€åœ¨çš„é”®å')

    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input_file):
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
        return
    
    # éªŒè¯å¹¶å‘æ•°
    if args.concurrency < 1:
        logger.error("å¹¶å‘æ•°å¿…é¡»å¤§äº0")
        return
    if args.concurrency > 20:
        logger.warning("å¹¶å‘æ•°è¿‡é«˜å¯èƒ½å¯¹æœåŠ¡å™¨é€ æˆå‹åŠ›ï¼Œå»ºè®®ä¸è¶…è¿‡20")

    # åˆ›å»ºå¤„ç†å™¨
    processor = UnifiedProcessor(args.server_ip, args.server_port)

    # å¤„ç†æ–‡ä»¶
    results = processor.process_file(args.input_file, args.max_items, args.line, args.debug, args.concurrency, args.lang, args.solution_key)

    # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
    if args.output:
        output_file = args.output
    else:
        # ä»è¾“å…¥æ–‡ä»¶åæå–è¯­è¨€ä¿¡æ¯ï¼Œç”Ÿæˆå¸¦è¯­è¨€å‰ç¼€çš„è¾“å‡ºæ–‡ä»¶å
        input_basename = os.path.basename(args.input_file)
        base_name = input_basename.replace('.jsonl', '')  # ä¾‹å¦‚ï¼štypescript.jsonl -> typescript

        # å¦‚æœæŒ‡å®šäº†è¯­è¨€è¿‡æ»¤ï¼Œåœ¨æ–‡ä»¶åä¸­ä½“ç°
        if args.lang:
            output_file = f"{base_name}_{args.lang}_results.jsonl"
        else:
            output_file = f"{base_name}_results.jsonl"

    # ä¿å­˜ç»“æœ
    if results:
        processor.save_results(results, output_file)
        
        # ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
        processor.print_detailed_statistics(results)
    else:
        logger.warning("æ²¡æœ‰å¤„ç†ä»»ä½•æ•°æ®")


if __name__ == "__main__":
    # æ‰§è¡Œä¸»å‡½æ•°
    main()