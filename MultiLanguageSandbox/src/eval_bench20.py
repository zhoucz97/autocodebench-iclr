#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified JSONL Processor

ç»Ÿä¸€çš„JSONLå¤„ç†å™¨ï¼Œæ”¯æŒå…¨éƒ¨è¯­è¨€çš„å¤„ç†ã€‚
å¯¹äºgoã€javaã€cppã€javascriptã€pythonè¿™5ä¸ªç‰¹æ®Šè¯­è¨€ï¼Œä½¿ç”¨format_test_codeå¤„ç†åï¼Œå°†å®Œæ•´ä»£ç ä½œä¸ºsource_codeä¼ ç»™submitæ¥å£ã€‚
å¯¹äºå…¶ä»–è¯­è¨€ï¼Œä½¿ç”¨ä¼ ç»Ÿçš„func_codeå’Œmain_codeæ–¹å¼ã€‚
"""

import json
import requests
import time
import argparse
import os
import logging
import re
import uuid
from typing import Dict, Any, List, Set
from multiprocessing import Pool, Manager, Queue
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm
from prettytable import PrettyTable

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('unified_processor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å…¨å±€å¤„ç†å™¨å®ä¾‹ï¼Œé¿å…é‡å¤åˆ›å»º
_global_processor = None


def init_worker(server_ip, server_port):
    """åˆå§‹åŒ–å·¥ä½œè¿›ç¨‹"""
    global _global_processor
    _global_processor = UnifiedProcessor(server_ip, server_port)


def process_single_data_worker(args):
    """å¤šè¿›ç¨‹å·¥ä½œå‡½æ•°ï¼Œå¤„ç†å•æ¡æ•°æ®"""
    data, index, debug = args
    global _global_processor

    # ä½¿ç”¨å…¨å±€å¤„ç†å™¨å®ä¾‹
    result = _global_processor.process_data(data, debug)
    result["index"] = index
    result["original_data"] = data

    return result


def process_single_data_worker(data, index, debug, print_code=False):
    """å•ä»»åŠ¡å·¥ä½œå‡½æ•°ï¼Œå¤„ç†ä¸€æ¡æ•°æ®"""
    global _global_processor

    result = _global_processor.process_data(data, debug, print_code)
    result["index"] = index
    result["original_data"] = data

    time.sleep(0.2)  # é€‚å½“å»¶è¿Ÿé¿å…APIè¿‡è½½
    return result


class UnifiedProcessor:
    def __init__(self, server_ip: str = "21.86.44.177", server_port: int = 8080):
        self.server_ip = server_ip
        self.server_port = server_port
        self.submit_url = f"http://{server_ip}:{server_port}/submit"
        self.headers = {
            "Content-Type": "application/json"
        }
        # éœ€è¦ç‰¹æ®Šå¤„ç†çš„è¯­è¨€ï¼ˆä½¿ç”¨format_test_codeï¼‰
        self.special_languages = []
        # self.special_languages = ["go", "java", "cpp", "javascript", "python"]

    def format_test_code(self, language: str, main_code: str, test_code: str, is_demo_test: bool = True) -> str:
        """ä½¿ç”¨format_test_codeé€»è¾‘å¤„ç†ç‰¹æ®Šè¯­è¨€çš„ä»£ç """
        if language == "javascript":
            if is_demo_test:
                code_req = main_code + "\n" + test_code + "\n\ndemoTesting()"
            else:
                code_req = main_code + "\n" + test_code + "\n\nfullTesting()"
        elif language == "go":
            import_info = self._go_extract_and_merge_imports([main_code, test_code])
            main_code = re.sub(r'import\s*(?:\(.*?\)|"[^"]+")\s*', '', main_code, flags=re.DOTALL)
            main_code = main_code.replace("package main", "")
            main_code = "package main\n" + import_info + "\n" + main_code
            test_code = re.sub(r'import\s*(?:\(.*?\)|"[^"]+")\s*', '', test_code, flags=re.DOTALL)
            test_code = test_code.replace("package main", "")
            if re.search(r'\s*func\s+Test\w+.+', test_code):
                go_test_method = "test"
            else:
                go_test_method = "main"
            if go_test_method == "main":
                main_func = "func main() {demoTesting()}" if is_demo_test else "func main() {fullTesting()}"
            else:
                main_func = ""
            code_req = main_code + "\n" + test_code + "\n\n" + main_func
            # åˆ é™¤æœªä½¿ç”¨åˆ°çš„importåŒ…
            code_req = self._go_remove_unused_imports(code_req)
        elif language == "cpp":
            model_func = main_code.strip().split("int main")[0]
            code_req = model_func + "\n" + test_code
            code_req = "#include <iostream>\nusing namespace std;\n" + code_req
        elif language == "java":
            # å°†ä¸»å‡½æ•°ä¸­çš„public classï¼Œprivate class å’Œ protected classéƒ½è½¬æˆclassã€‚
            main_code = main_code.replace("public class", "class").replace("private class", "class").replace("protected class", "class")
            # æå–ç”¨åˆ°çš„åŒ…
            answer_packages = [line for line in main_code.split('\n') if line.startswith("import ")]
            # å°†packageå¼€å¤´çš„è¡Œä»¥åŠå¯¼å…¥åŒ…çš„è¡Œå»é™¤
            answer_code = [line for line in main_code.split('\n') if not (line.startswith("import ") or line.startswith("package "))]
            answer_code = "\n".join(answer_code)
            # æå–æµ‹è¯•å‡½æ•°çš„ç”¨åˆ°çš„åŒ…
            test_packages = [line for line in test_code.split('\n') if line.startswith("import ")]
            # å¯¹å¯¼å…¥çš„åŒ…å»é‡
            all_packages = answer_packages + test_packages
            all_packages = list(set(all_packages))
            all_packages = "\n".join(all_packages)
            # å°†packageå¼€å¤´çš„è¡Œä»¥åŠå¯¼å…¥åŒ…çš„è¡Œå»é™¤
            test_code = [line for line in test_code.split('\n') if not (line.startswith("import ") or line.startswith("package "))]
            test_code = "\n".join(test_code)
            # æ‹¼æ¥
            code_req = all_packages + "\n" + answer_code + "\n" + test_code
        elif language == "python":
            code_req = main_code + "\n" + test_code
        else:
            raise Exception(f"ä¸æ”¯æŒçš„è¯­è¨€ç±»å‹ï¼š{language}")
        return code_req
    
    def _go_extract_and_merge_imports(self, code_blocks: list):
        """æå–å¹¶åˆå¹¶Goä»£ç ä¸­çš„importè¯­å¥"""
        imports = set()
        for code in code_blocks:
            # åŒ¹é…å¸¦æ‹¬å·çš„å¤šè¡Œimportå’Œå•è¡Œimport
            matches = re.findall(r'import\s*(?:\((.*?)\)|"([^"]+)")', code, re.DOTALL)
            for match in matches:
                # å¤„ç†ä¸¤ç§åŒ¹é…ç»“æœ
                for imp in match:
                    if imp.strip():
                        # åˆ†å‰²å¤šè¡Œimportä¸­çš„å„ä¸ªåŒ…
                        for line in imp.split('\n'):
                            line = line.strip()
                            if line and not line.startswith('//'):  # å¿½ç•¥æ³¨é‡Š
                                # å»é™¤å¯èƒ½çš„å¼•å·å’Œåˆ†å·
                                line = line.replace('"', '').replace(';', '').strip()
                                if line:
                                    imports.add(line)

        # ç”Ÿæˆåˆå¹¶åçš„importè¯­å¥
        if imports:
            merged_import = "import (\n"
            for imp in imports:
                merged_import += f'    "{imp}"\n'
            merged_import += ")"
        else:
            merged_import = ""

        return merged_import

    def _go_remove_unused_imports(self, go_code: str) -> str:
        """ç§»é™¤Goä»£ç ä¸­æœªä½¿ç”¨çš„importåŒ…"""
        # 1. æ‰¾å‡ºæ‰€æœ‰importè¯­å¥ï¼ˆåŒ…æ‹¬åˆ†ç»„å’Œç‹¬ç«‹importï¼‰
        imports = []

        # å¤„ç†åˆ†ç»„import (import (...))
        for match in re.finditer(r'import\s*\(([\s\S]*?)\)', go_code):
            imports.append(('grouped', match.start(), match.end(), match.group(1)))

        # å¤„ç†ç‹¬ç«‹import (import "pkg")
        for match in re.finditer(r'import\s+"([^"]+)"', go_code):
            imports.append(('single', match.start(), match.end(), match.group(1)))

        # å¦‚æœæ²¡æœ‰importè¯­å¥ï¼Œç›´æ¥è¿”å›
        if not imports:
            return go_code

        # 2. æ”¶é›†æ‰€æœ‰å¯¼å…¥çš„åŒ…
        imported_pkgs = set()
        for imp_type, start, end, content in imports:
            if imp_type == 'grouped':
                # ä»åˆ†ç»„ä¸­æå–æ‰€æœ‰åŒ…
                imported_pkgs.update(re.findall(r'"([^"]+)"', content))
            else:  # single
                imported_pkgs.add(content)

        # 3. æ‰¾å‡ºå®é™…ä½¿ç”¨çš„åŒ…
        used_pkgs: Set[str] = set()
        for pkg in imported_pkgs:
            pkg_identifier = pkg.split('/')[-1]
            # æ’é™¤importéƒ¨åˆ†æ£€æŸ¥ä½¿ç”¨æƒ…å†µ
            code_without_imports = go_code
            for _, start, end, _ in imports:
                code_without_imports = code_without_imports[:start] + ' ' * (end - start) + code_without_imports[end:]
            pkg_identifier = re.escape(pkg_identifier)
            if re.search(rf'(?<!\w){pkg_identifier}(?!\w)', code_without_imports):
                used_pkgs.add(pkg)

        # 4. é‡å»ºä»£ç 
        result = []
        last_pos = 0

        for imp_type, start, end, content in sorted(imports, key=lambda x: x[1]):
            # æ·»åŠ importä¹‹å‰çš„ä»£ç 
            result.append(go_code[last_pos:start])

            if imp_type == 'grouped':
                # å¤„ç†åˆ†ç»„import
                new_lines = []
                for line in content.split('\n'):
                    line = line.strip()
                    if not line:
                        new_lines.append('')
                        continue
                    pkg = re.search(r'"([^"]+)"', line)
                    if pkg and pkg.group(1) in used_pkgs:
                        new_lines.append(line)

                if new_lines:
                    result.append(f'import (\n' + '\n'.join(new_lines) + '\n)')
            else:  # single
                # å¤„ç†ç‹¬ç«‹import
                if content in used_pkgs:
                    result.append(f'import "{content}"')

            last_pos = end

        # æ·»åŠ æœ€åéƒ¨åˆ†ä»£ç 
        result.append(go_code[last_pos:])

        return ''.join(result)
 
    def read_jsonl_file(self, file_path: str, line_number: int = None, target_language: str = None) -> List[Dict[str, Any]]:
        """è¯»å–JSONLæ–‡ä»¶å¹¶è¿”å›æ•°æ®åˆ—è¡¨"""
        data_list = []
        total_count = 0
        filtered_count = 0

        try:
            # å¦‚æœæŒ‡å®šäº†è¡Œå·ï¼Œéœ€è¦ä¸¤éå¤„ç†ï¼šç¬¬ä¸€éç»Ÿè®¡ï¼Œç¬¬äºŒéé€‰æ‹©
            if line_number is not None:
                # ç¬¬ä¸€éï¼šç»Ÿè®¡æ€»æ•°æ®å’ŒåŒ¹é…æ•°æ®
                with open(file_path, 'r', encoding='utf-8') as file:
                    for line_num, line in enumerate(file, 1):
                        line = line.strip()
                        if line:
                            try:
                                data = json.loads(line)
                                total_count += 1

                                # è¯­è¨€è¿‡æ»¤ç»Ÿè®¡
                                if target_language:
                                    data_language = data.get("language", "").lower()
                                    if data_language == target_language.lower():
                                        filtered_count += 1
                                else:
                                    filtered_count += 1
                            except json.JSONDecodeError as e:
                                logger.error(f"ç¬¬{line_num}è¡ŒJSONè§£æé”™è¯¯: {e}")
                                continue

                # ç¬¬äºŒéï¼šé€‰æ‹©æŒ‡å®šè¡Œå·çš„æ•°æ®
                current_filtered = 0
                with open(file_path, 'r', encoding='utf-8') as file:
                    for line_num, line in enumerate(file, 1):
                        line = line.strip()
                        if line:
                            try:
                                data = json.loads(line)

                                # è¯­è¨€è¿‡æ»¤
                                if target_language:
                                    data_language = data.get("language", "").lower()
                                    if data_language != target_language.lower():
                                        continue

                                current_filtered += 1
                                if current_filtered == line_number:
                                    # æ·»åŠ ç»å¯¹è¡Œå·ä¿¡æ¯
                                    data['_absolute_line_number'] = line_num
                                    data['_relative_line_number'] = current_filtered
                                    data_list.append(data)
                                    break
                            except json.JSONDecodeError as e:
                                continue
            else:
                # æ²¡æœ‰æŒ‡å®šè¡Œå·ï¼Œéœ€è¦ä¸¤éå¤„ç†æ¥æ­£ç¡®è®¡ç®—ç›¸å¯¹è¡Œå·
                # ç¬¬ä¸€éï¼šä¸ºæ¯ç§è¯­è¨€å»ºç«‹è¡Œå·æ˜ å°„
                language_line_mapping = {}  # {language: [(absolute_line, data), ...]}

                with open(file_path, 'r', encoding='utf-8') as file:
                    for line_num, line in enumerate(file, 1):
                        line = line.strip()
                        if line:
                            try:
                                data = json.loads(line)
                                total_count += 1

                                data_language = data.get("language", "").lower()

                                # è¯­è¨€è¿‡æ»¤
                                if target_language:
                                    if data_language != target_language.lower():
                                        continue

                                # ä¸ºæ¯ç§è¯­è¨€å»ºç«‹æ˜ å°„
                                if data_language not in language_line_mapping:
                                    language_line_mapping[data_language] = []

                                language_line_mapping[data_language].append((line_num, data))
                                filtered_count += 1

                            except json.JSONDecodeError as e:
                                logger.error(f"ç¬¬{line_num}è¡ŒJSONè§£æé”™è¯¯: {e}")
                                continue

                # ç¬¬äºŒéï¼šä¸ºæ¯ç§è¯­è¨€çš„æ•°æ®åˆ†é…ç›¸å¯¹è¡Œå·
                for language, lang_data_list in language_line_mapping.items():
                    for relative_line_num, (absolute_line_num, data) in enumerate(lang_data_list, 1):
                        # æ·»åŠ ç»å¯¹è¡Œå·å’Œç›¸å¯¹è¡Œå·ä¿¡æ¯ï¼ˆç›¸å¯¹è¡Œå·æ˜¯åœ¨è¯¥è¯­è¨€å†…çš„è¡Œå·ï¼‰
                        data['_absolute_line_number'] = absolute_line_num
                        data['_relative_line_number'] = relative_line_num
                        data_list.append(data)

                # æŒ‰ç»å¯¹è¡Œå·æ’åºï¼Œä¿æŒåŸå§‹æ–‡ä»¶é¡ºåº
                data_list.sort(key=lambda x: x['_absolute_line_number'])

            if target_language:
                logger.info(f"è¯­è¨€è¿‡æ»¤: {target_language} - æ€»æ•°æ®{total_count}æ¡ï¼ŒåŒ¹é…{filtered_count}æ¡ï¼Œæœ€ç»ˆè¯»å–{len(data_list)}æ¡")
            else:
                logger.info(f"æˆåŠŸè¯»å–{len(data_list)}æ¡æ•°æ®")
            return data_list
        except FileNotFoundError:
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return []
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []


    def extract_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æå–éœ€è¦çš„å­—æ®µï¼Œå¦‚æœç›´æ¥æå–å¤±è´¥åˆ™å°è¯•ä»original_dataå­—æ®µè·å–"""
        def get_field_with_fallback(field_name: str, default_value: str = "") -> str:
            """ä»dataæˆ–original_dataä¸­è·å–å­—æ®µå€¼"""
            # é¦–å…ˆå°è¯•ç›´æ¥ä»dataä¸­è·å–
            value = data.get(field_name, "")
            if value:  # å¦‚æœæœ‰å€¼å°±ç›´æ¥è¿”å›
                return value

            # å¦‚æœæ²¡æœ‰å€¼ï¼Œå°è¯•ä»original_dataä¸­è·å–
            original_data = data.get("original_data", {})
            if isinstance(original_data, dict):
                return original_data.get(field_name, default_value)

            return default_value

        def get_main_test_func_with_fallback() -> str:
            """ç‰¹æ®Šå¤„ç†main_test_funcå­—æ®µï¼Œæ”¯æŒä»outputå­—æ®µæå–ä»£ç å—"""
            # é¦–å…ˆå°è¯•ç›´æ¥ä»dataä¸­è·å–
            value = data.get("main_test_func", "")
            if value:
                return value

            # å¦‚æœæ²¡æœ‰å€¼ï¼Œå°è¯•ä»original_dataä¸­è·å–
            original_data = data.get("original_data", {})
            if isinstance(original_data, dict):
                # å…ˆå°è¯•ä»outputå­—æ®µæå–
                output = original_data.get("output", "")
                if output:
                    return self._extract_code_from_output(output)

                # å¦‚æœæ²¡æœ‰outputï¼Œå°è¯•ä»main_test_funcå­—æ®µæå–
                main_test_func = original_data.get("main_test_func", "")
                if main_test_func:
                    return main_test_func


            return ""

        # æå–å„ä¸ªå­—æ®µï¼Œlanguageéœ€è¦è½¬ä¸ºå°å†™
        language = get_field_with_fallback("language", "").lower()

        return {
            "language": language,
            "full_test_func": get_field_with_fallback("full_test_func", ""),
            "demo_test_func": get_field_with_fallback("demo_test_func", ""),
            "main_test_func": get_main_test_func_with_fallback()
        }

    def _extract_code_from_output(self, output: str) -> str:
        """ä»outputå­—æ®µä¸­æå–ä»£ç å—ï¼Œæ ¼å¼ä¸º ```{language}\n{code}```"""
        if not output:
            return ""

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä»£ç å—
        matches = re.finditer(r'```(\w+)\n(.*?)```', output, flags=re.DOTALL)

        for match in matches:
            language = match.group(1)
            code = match.group(2).strip()
            if code:  # å¦‚æœæå–åˆ°äº†ä»£ç ï¼Œè¿”å›ç¬¬ä¸€ä¸ªéç©ºçš„ä»£ç å—
                return code

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ ‡å‡†æ ¼å¼ï¼Œå°è¯•ç®€å•çš„å»æ‰é¦–è¡Œå¤„ç†
        # å…ˆå»æ‰å¼€å§‹å’Œç»“å°¾çš„```ç¬¦å·
        cleaned_output = output.strip()
        if cleaned_output.startswith('```'):
            cleaned_output = cleaned_output[3:]
        if cleaned_output.endswith('```'):
            cleaned_output = cleaned_output[:-3]

        lines = cleaned_output.strip().split('\n')
        if len(lines) > 1:
            # å»æ‰ç¬¬ä¸€è¡Œï¼Œè¿”å›å‰©ä½™å†…å®¹
            return '\n'.join(lines[1:]).strip()

        return cleaned_output.strip()


    def call_submit_api(self, data: Dict[str, Any], test_type: str = "full", debug: bool = False, print_code: bool = False) -> Dict[str, Any]:
        """è°ƒç”¨submitæ¥å£"""
        try:
            language = data["language"]
            is_special_language = language in self.special_languages
            
            # æ ¹æ®æµ‹è¯•ç±»å‹é€‰æ‹©æµ‹è¯•ä»£ç 
            if test_type == "full":
                test_code = data["full_test_func"]
            elif test_type == "demo":
                test_code = data["demo_test_func"]
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æµ‹è¯•ç±»å‹: {test_type}")
            
            if is_special_language:
                # ç‰¹æ®Šè¯­è¨€ï¼šä½¿ç”¨format_test_codeå¤„ç†ï¼Œå°†å®Œæ•´ä»£ç ä½œä¸ºsource_code
                is_demo_test = (test_type == "demo")
                formatted_code = self.format_test_code(
                    language, 
                    data["main_test_func"], 
                    test_code, 
                    is_demo_test
                )
                
                # åœ¨æŒ‡å®šè¡Œæ¨¡å¼ä¸‹æ‰“å°formatted_code
                if print_code:
                    print(f"\n{'='*80}")
                    print(f"ğŸ” {test_type.upper()} æµ‹è¯• - {language.upper()} æ ¼å¼åŒ–ä»£ç :")
                    print(f"{'='*80}")
                    print(formatted_code)
                    print(f"{'='*80}\n")

                # ç¡®å®šGoæµ‹è¯•æ–¹æ³•
                if language == "go" and re.search(r'\s*func\s+Test\w+.+', test_code):
                    go_test_method = "test"
                else:
                    go_test_method = "main"
                
                payload = {
                    "src_uid": str(uuid.uuid4()),
                    "sandbox_type": "General",
                    "source_code": formatted_code,  # ä½¿ç”¨æ ¼å¼åŒ–åçš„å®Œæ•´ä»£ç 
                    "lang": language,
                    "show_log": True,
                    "request_extensions": {
                        "timeout": 30.0,
                        "debug": str(debug).lower(),
                        "go_test_method": go_test_method,
                        "target": "test",
                    }
                }
            else:
                # æ™®é€šè¯­è¨€ï¼šä½¿ç”¨ä¼ ç»Ÿçš„func_codeå’Œmain_codeæ–¹å¼
                payload = {
                    "src_uid": f"0710_bench_test_{test_type}_{int(time.time())}",
                    "func_code": data["main_test_func"],
                    "main_code": test_code,
                    "lang": language,
                    "show_log": "true",
                    "request_extensions": {"timeout": 30, "debug": str(debug).lower()}
                }
            
            # Debugæ¨¡å¼ä¸‹è¾“å‡ºè¯·æ±‚å†…å®¹
            if debug:
                print(f"\n{'='*80}")
                print(f"ğŸš€ DEBUG - REQUEST è¯·æ±‚å†…å®¹:")
                print(f"{'='*80}")
                print(f"URL: {self.submit_url}")
                print(f"Headers: {json.dumps(self.headers, indent=2, ensure_ascii=False)}")
                print(f"Payload:")
                # ä¸ºäº†å¯è¯»æ€§ï¼Œå¯¹payloadè¿›è¡Œæ ¼å¼åŒ–è¾“å‡º
                payload_copy = payload.copy()
                if 'source_code' in payload_copy and len(payload_copy['source_code']) > 500:
                    # å¦‚æœsource_codeå¤ªé•¿ï¼Œåªæ˜¾ç¤ºå‰åéƒ¨åˆ†
                    code = payload_copy['source_code']
                    payload_copy['source_code'] = f"{code[:200]}...\n[ä»£ç å¤ªé•¿ï¼Œçœç•¥ä¸­é—´éƒ¨åˆ†ï¼Œæ€»é•¿åº¦: {len(code)} å­—ç¬¦]\n...{code[-200:]}"
                print(json.dumps(payload_copy, indent=2, ensure_ascii=False))
                print(f"{'='*80}\n")

            # logger.info(f"è°ƒç”¨submitæ¥å£ï¼Œæµ‹è¯•ç±»å‹: {test_type}, è¯­è¨€: {language}, ç‰¹æ®Šå¤„ç†: {is_special_language}, debug: {debug}")
            response = requests.post(self.submit_url, headers=self.headers, json=payload, timeout=60)
            
            # Debugæ¨¡å¼ä¸‹è¾“å‡ºå“åº”å†…å®¹
            if debug:
                print(f"\n{'='*80}")
                print(f"ğŸ“¥ DEBUG - RESPONSE å“åº”å†…å®¹:")
                print(f"{'='*80}")
                print(f"Status Code: {response.status_code}")
                print(f"Response Headers: {dict(response.headers)}")
                try:
                    response_json = response.json()
                    print(f"Response Body:")
                    print(json.dumps(response_json, indent=2, ensure_ascii=False))
                except:
                    print(f"Response Text: {response.text}")
                print(f"{'='*80}\n")

            if response.status_code == 200:
                result = response.json()
                # logger.info(f"APIè°ƒç”¨æˆåŠŸï¼Œ{test_type}ï¼Œç»“æœ: {result.get('exec_outcome', 'unknown')}")
                return {
                    "success": True,
                    "response": result,
                    "status_code": response.status_code
                }
            else:
                logger.error(f"APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}: {response.text}",
                    "status_code": response.status_code
                }
                
        except requests.exceptions.Timeout:
            logger.error("APIè°ƒç”¨è¶…æ—¶")
            return {
                "success": False,
                "error": "è¯·æ±‚è¶…æ—¶",
                "status_code": None
            }
        except requests.exceptions.RequestException as e:
            logger.error(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": str(e),
                "status_code": None
            }
        except Exception as e:
            logger.error(f"å¤„ç†æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {
                "success": False,
                "error": str(e),
                "status_code": None
            }
    
    def process_data(self, data: Dict[str, Any], debug: bool = False, print_code: bool = False) -> Dict[str, Any]:
        """å¤„ç†å•æ¡æ•°æ®ï¼Œè°ƒç”¨ä¸¤æ¬¡submitæ¥å£"""
        extracted_data = self.extract_fields(data)
        
        # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨ï¼Œæä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        missing_fields = []
        for field_name, field_value in extracted_data.items():
            if not field_value or field_value.strip() == "":
                missing_fields.append(field_name)

        if missing_fields:
            error_msg = f"ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}"
            logger.warning(f"{error_msg}ï¼ŒåŸå§‹æ•°æ®é”®: {list(data.keys())}")

            # å¦‚æœæœ‰original_dataï¼Œä¹Ÿæ‰“å°å…¶é”®
            if "original_data" in data and isinstance(data["original_data"], dict):
                logger.warning(f"original_dataé”®: {list(data['original_data'].keys())}")

            return {
                "success": False,
                "error": error_msg,
                "full_test_result": None,
                "demo_test_result": None,
                "language": extracted_data.get("language", "unknown"),
                "missing_fields": missing_fields
            }
        
        # è°ƒç”¨full_test_func
        full_test_result = self.call_submit_api(extracted_data, "full", debug, print_code)

        # ç­‰å¾…ä¸€ç§’å†è°ƒç”¨demo_test_func
        time.sleep(1)
        
        # è°ƒç”¨demo_test_func
        demo_test_result = self.call_submit_api(extracted_data, "demo", debug, print_code)

        # åˆ¤æ–­æ•´ä½“æ˜¯å¦æˆåŠŸï¼ˆä¸¤ä¸ªAPIè°ƒç”¨éƒ½æˆåŠŸä¸”ä»£ç æ‰§è¡Œéƒ½é€šè¿‡æ‰ç®—æˆåŠŸï¼‰
        full_api_success = full_test_result.get("success", False)
        demo_api_success = demo_test_result.get("success", False)
        
        # æ£€æŸ¥ä»£ç æ‰§è¡Œç»“æœ
        full_exec_passed = (full_api_success and 
                           full_test_result.get("response", {}).get("exec_outcome") == "PASSED")
        demo_exec_passed = (demo_api_success and 
                           demo_test_result.get("response", {}).get("exec_outcome") == "PASSED")
        
        # æ•´ä½“æˆåŠŸï¼šä¸¤ä¸ªAPIè°ƒç”¨éƒ½æˆåŠŸä¸”ä»£ç æ‰§è¡Œéƒ½é€šè¿‡
        overall_success = full_exec_passed and demo_exec_passed
        
        # åœ¨æŒ‡å®šè¡Œæ¨¡å¼ä¸‹ï¼Œå¦‚æœæµ‹è¯•å¤±è´¥ï¼Œæ‰“å°å®Œæ•´çš„responseä¿¡æ¯
        if print_code and not overall_success:
            print(f"\n{'='*80}")
            print(f"âŒ æµ‹è¯•å¤±è´¥è¯¦æƒ… - {extracted_data['language'].upper()}")
            print(f"{'='*80}")

            # æ‰“å°FULLæµ‹è¯•ç»“æœ
            print(f"\nğŸ” FULL æµ‹è¯•ç»“æœ:")
            print(f"   APIè°ƒç”¨æˆåŠŸ: {full_api_success}")
            print(f"   æ‰§è¡Œç»“æœ: {full_test_result.get('response', {}).get('exec_outcome', 'unknown')}")
            if full_test_result.get("response"):
                print(f"   å®Œæ•´å“åº”:")
                print(json.dumps(full_test_result["response"], indent=2, ensure_ascii=False))
            elif full_test_result.get("error"):
                print(f"   é”™è¯¯ä¿¡æ¯: {full_test_result['error']}")

            # æ‰“å°DEMOæµ‹è¯•ç»“æœ
            print(f"\nğŸ” DEMO æµ‹è¯•ç»“æœ:")
            print(f"   APIè°ƒç”¨æˆåŠŸ: {demo_api_success}")
            print(f"   æ‰§è¡Œç»“æœ: {demo_test_result.get('response', {}).get('exec_outcome', 'unknown')}")
            if demo_test_result.get("response"):
                print(f"   å®Œæ•´å“åº”:")
                print(json.dumps(demo_test_result["response"], indent=2, ensure_ascii=False))
            elif demo_test_result.get("error"):
                print(f"   é”™è¯¯ä¿¡æ¯: {demo_test_result['error']}")

            print(f"{'='*80}\n")

        return {
            "success": overall_success,
            "full_test_result": full_test_result,
            "demo_test_result": demo_test_result,
            "language": extracted_data["language"]
        }
    
    def process_file(self, file_path: str, max_items: int = None, line_number: int = None,
                     debug: bool = False, concurrency: int = 5, target_language: str = None) -> List[Dict[str, Any]]:
        """å¤„ç†æ•´ä¸ªJSONLæ–‡ä»¶"""
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")
        if target_language:
            logger.info(f"è¯­è¨€è¿‡æ»¤: åªå¤„ç† {target_language} è¯­è¨€çš„æ•°æ®")

        # è¯»å–æ•°æ®
        data_list = self.read_jsonl_file(file_path, line_number, target_language)
        if not data_list:
            return []
        
        # é™åˆ¶å¤„ç†æ•°é‡ï¼ˆåªæœ‰åœ¨æ²¡æœ‰æŒ‡å®šè¡Œå·æ—¶æ‰ç”Ÿæ•ˆï¼‰
        if max_items and line_number is None:
            data_list = data_list[:max_items]
            logger.info(f"é™åˆ¶å¤„ç†æ•°é‡ä¸º: {max_items}")
        
        # å¦‚æœåªæœ‰ä¸€æ¡æ•°æ®æˆ–æŒ‡å®šäº†è¡Œå·ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†
        if len(data_list) == 1 or line_number is not None:
            logger.info("ä½¿ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼")
            return self._process_file_serial(data_list, line_number, debug)

        # ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†
        logger.info(f"ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†æ¨¡å¼ï¼Œå¹¶å‘æ•°: {concurrency}")
        return self._process_file_multiprocess(data_list, debug, concurrency)

    def _process_file_serial(self, data_list: List[Dict[str, Any]], line_number: int = None,
                           debug: bool = False) -> List[Dict[str, Any]]:
        """ä¸²è¡Œå¤„ç†æ–‡ä»¶"""
        results = []

        # åˆ¤æ–­æ˜¯å¦ä¸ºæŒ‡å®šè¡Œæ¨¡å¼ï¼ˆç”¨äºæ‰“å°ä»£ç ï¼‰
        is_single_line_mode = line_number is not None

        # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
        desc = f"å¤„ç†ç¬¬{line_number}è¡Œæ•°æ®" if line_number else "ä¸²è¡Œå¤„ç†"
        with tqdm(total=len(data_list), desc=desc, unit="æ¡") as pbar:
            for i, data in enumerate(data_list, 1):
                result = self.process_data(data, debug, print_code=is_single_line_mode)
                result["index"] = i
                result["original_data"] = data
                results.append(result)

                # æ›´æ–°è¿›åº¦æ¡
                pbar.update(1)
                pbar.set_postfix({
                    "æˆåŠŸ": sum(1 for r in results if r.get("success", False)),
                    "å¤±è´¥": sum(1 for r in results if not r.get("success", False))
                })

                # åœ¨æ¯æ¬¡å¤„ç†ä¹‹é—´ç¨ä½œç­‰å¾…ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                if i < len(data_list):
                    time.sleep(0.5)

        logger.info(f"ä¸²è¡Œå¤„ç†å®Œæˆï¼Œå…±å¤„ç†{len(results)}æ¡æ•°æ®")
        return results
    
    def _process_file_multiprocess(self, data_list: List[Dict[str, Any]], debug: bool = False,
                                 concurrency: int = 5) -> List[Dict[str, Any]]:
        """å¤šè¿›ç¨‹å¤„ç†æ–‡ä»¶ - ç®€åŒ–ç‰ˆæœ¬"""
        total_items = len(data_list)

        # å¦‚æœæ•°æ®é‡å°ï¼Œç›´æ¥ä½¿ç”¨ä¸²è¡Œå¤„ç†
        if total_items < concurrency:
            logger.info(f"æ•°æ®é‡è¾ƒå°({total_items}æ¡)ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†")
            return self._process_file_serial(data_list, debug=debug)

        logger.info(f"å¯åŠ¨{concurrency}ä¸ªè¿›ç¨‹å¤„ç†{total_items}æ¡æ•°æ®")

        results = []
        try:
            # ä½¿ç”¨è¿›ç¨‹æ± ï¼Œæ¯ä¸ªä»»åŠ¡å¤„ç†ä¸€æ¡æ•°æ®
            with Pool(processes=concurrency, initializer=init_worker, initargs=(self.server_ip, self.server_port)) as pool:
                # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
                with tqdm(total=total_items, desc=f"å¤šè¿›ç¨‹å¤„ç†({concurrency}è¿›ç¨‹)", unit="æ¡") as pbar:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    futures = []
                    for i, data in enumerate(data_list, 1):
                        future = pool.apply_async(process_single_data_worker, (data, i, debug, False))
                        futures.append(future)

                    # æ”¶é›†ç»“æœ
                    for future in futures:
                        try:
                            result = future.get(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                            results.append(result)
                            pbar.update(1)

                            # æ›´æ–°è¿›åº¦æ¡ç»Ÿè®¡
                            pbar.set_postfix({
                                "æˆåŠŸ": sum(1 for r in results if r.get("success", False)),
                                "å¤±è´¥": sum(1 for r in results if not r.get("success", False))
                            })
                        except Exception as e:
                            logger.error(f"ä»»åŠ¡å¤±è´¥: {e}")
                            # åˆ›å»ºå¤±è´¥ç»“æœ
                            failed_result = {
                                "index": len(results) + 1,
                                "success": False,
                                "error": str(e),
                                "original_data": {}
                            }
                            results.append(failed_result)
                            pbar.update(1)

        except Exception as e:
            logger.error(f"å¤šè¿›ç¨‹å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            # å¦‚æœå¤šè¿›ç¨‹å¤±è´¥ï¼Œå›é€€åˆ°ä¸²è¡Œå¤„ç†
            logger.info("å›é€€åˆ°ä¸²è¡Œå¤„ç†æ¨¡å¼")
            return self._process_file_serial(data_list, debug=debug)

        # æŒ‰indexæ’åºç»“æœ
        results.sort(key=lambda x: x.get("index", 0))

        logger.info(f"å¤šè¿›ç¨‹å¤„ç†å®Œæˆï¼Œå…±å¤„ç†{len(results)}æ¡æ•°æ®")
        return results

    def save_results(self, results: List[Dict[str, Any]], output_file: str):
        """ä¿å­˜å¤„ç†ç»“æœåˆ°æ–‡ä»¶"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                for result in results:
                    # ç®€åŒ–è¾“å‡ºæ ¼å¼ï¼Œåªä¿ç•™å¿…è¦ä¿¡æ¯
                    simplified_result = {
                        "index": result.get("index", 0),
                        "language": result.get("language", ""),
                        "success": result.get("success", False),
                        "full_test_outcome": result.get("full_test_result", {}).get("response", {}).get("exec_outcome", "unknown"),
                        "demo_test_outcome": result.get("demo_test_result", {}).get("response", {}).get("exec_outcome", "unknown"),
                        "full_test_output": result.get("full_test_result", {}).get("response", {}).get("exec_cout", ""),
                        "demo_test_output": result.get("demo_test_result", {}).get("response", {}).get("exec_cout", ""),
                        "full_test_error": result.get("full_test_result", {}).get("error", ""),
                        "demo_test_error": result.get("demo_test_result", {}).get("error", "")
                    }
                    f.write(json.dumps(simplified_result, ensure_ascii=False) + '\n')
            logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}")

    def print_detailed_statistics(self, results: List[Dict[str, Any]]):
        """æ‰“å°è¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Šè¡¨æ ¼"""
        if not results:
            print("\nâŒ æ²¡æœ‰å¤„ç†ä»»ä½•æ•°æ®")
            return

        # æŒ‰è¯­è¨€åˆ†ç»„ç»Ÿè®¡
        language_stats = {}
        failed_items = []

        for result in results:
            language = result.get("language", "unknown")
            success = result.get("success", False)
            index = result.get("index", 0)

            # åˆå§‹åŒ–è¯­è¨€ç»Ÿè®¡
            if language not in language_stats:
                language_stats[language] = {
                    "total": 0,
                    "success": 0,
                    "failed": 0,
                    "full_passed": 0,
                    "demo_passed": 0,
                    "both_passed": 0,
                    "failed_indices": []
                }

            # æ›´æ–°ç»Ÿè®¡
            stats = language_stats[language]
            stats["total"] += 1

            if success:
                stats["success"] += 1
            else:
                stats["failed"] += 1
                # è·å–ç»å¯¹è¡Œå·å’Œç›¸å¯¹è¡Œå·
                absolute_line = result.get("original_data", {}).get("_absolute_line_number", index)
                relative_line = result.get("original_data", {}).get("_relative_line_number", index)

                stats["failed_indices"].append({
                    "absolute_line": absolute_line,
                    "relative_line": relative_line
                })
                failed_items.append({
                    "index": index,
                    "absolute_line": absolute_line,
                    "relative_line": relative_line,
                    "language": language,
                    "full_outcome": result.get("full_test_result", {}).get("response", {}).get("exec_outcome", "unknown"),
                    "demo_outcome": result.get("demo_test_result", {}).get("response", {}).get("exec_outcome", "unknown"),
                    "full_error": result.get("full_test_result", {}).get("error", ""),
                    "demo_error": result.get("demo_test_result", {}).get("error", "")
                })

            # è¯¦ç»†æµ‹è¯•ç»“æœç»Ÿè®¡
            full_outcome = result.get("full_test_result", {}).get("response", {}).get("exec_outcome", "")
            demo_outcome = result.get("demo_test_result", {}).get("response", {}).get("exec_outcome", "")

            if full_outcome == "PASSED":
                stats["full_passed"] += 1
            if demo_outcome == "PASSED":
                stats["demo_passed"] += 1
            if full_outcome == "PASSED" and demo_outcome == "PASSED":
                stats["both_passed"] += 1

        # æ‰“å°æ€»ä½“ç»Ÿè®¡
        total_items = len(results)
        total_success = sum(1 for r in results if r.get("success", False))
        total_failed = total_items - total_success

        print("\n" + "="*80)
        print("ğŸ¯ æ‰§è¡Œç»“æœç»Ÿè®¡æŠ¥å‘Š")
        print("="*80)

        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»å¤„ç†æ•°æ®: {total_items} æ¡")
        print(f"   æˆåŠŸæ•°æ®:   {total_success} æ¡ ({total_success/total_items*100:.1f}%)")
        print(f"   å¤±è´¥æ•°æ®:   {total_failed} æ¡ ({total_failed/total_items*100:.1f}%)")

        # ä½¿ç”¨ PrettyTable æ‰“å°å„è¯­è¨€è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼
        print(f"\nğŸ“‹ å„è¯­è¨€è¯¦ç»†ç»Ÿè®¡:")
        language_table = PrettyTable()
        language_table.field_names = ["è¯­è¨€", "æ€»æ•°", "æˆåŠŸ", "å¤±è´¥", "æˆåŠŸç‡", "Demoé€šè¿‡", "Fullé€šè¿‡", "åŒé€šè¿‡"]
        language_table.align = "l"
        language_table.align["æ€»æ•°"] = "r"
        language_table.align["æˆåŠŸ"] = "r"
        language_table.align["å¤±è´¥"] = "r"
        language_table.align["æˆåŠŸç‡"] = "r"
        language_table.align["Demoé€šè¿‡"] = "r"
        language_table.align["Fullé€šè¿‡"] = "r"
        language_table.align["åŒé€šè¿‡"] = "r"

        # æŒ‰è¯­è¨€åç§°æ’åºæ·»åŠ æ•°æ®
        for language in sorted(language_stats.keys()):
            stats = language_stats[language]
            success_rate = stats["success"] / stats["total"] * 100 if stats["total"] > 0 else 0

            language_table.add_row([
                language,
                stats["total"],
                stats["success"],
                stats["failed"],
                f"{success_rate:.1f}%",
                stats["demo_passed"],
                stats["full_passed"],
                stats["both_passed"]
            ])

        print(language_table)

        # ä½¿ç”¨ PrettyTable æ‰“å°å¤±è´¥æ•°æ®è¯¦æƒ…
        if failed_items:
            print(f"\nâŒ å¤±è´¥æ•°æ®è¯¦æƒ… (å…±{len(failed_items)}æ¡):")
            failed_table = PrettyTable()
            failed_table.field_names = ["ç»å¯¹è¡Œå·", "ç›¸å¯¹è¡Œå·", "è¯­è¨€", "Fullæµ‹è¯•", "Demoæµ‹è¯•", "é”™è¯¯ä¿¡æ¯"]
            failed_table.align = "l"
            failed_table.align["ç»å¯¹è¡Œå·"] = "r"
            failed_table.align["ç›¸å¯¹è¡Œå·"] = "r"
            failed_table.max_width["é”™è¯¯ä¿¡æ¯"] = 40

            for item in sorted(failed_items, key=lambda x: x["absolute_line"]):  # æŒ‰ç»å¯¹è¡Œå·æ’åº
                # è·å–ä¸»è¦é”™è¯¯ä¿¡æ¯
                error_msg = ""
                if item["full_error"]:
                    error_msg = item["full_error"]
                elif item["demo_error"]:
                    error_msg = item["demo_error"]
                else:
                    error_msg = "æ‰§è¡Œæœªé€šè¿‡"

                # æˆªæ–­è¿‡é•¿çš„é”™è¯¯ä¿¡æ¯
                if len(error_msg) > 48:
                    error_msg = error_msg[:45] + "..."

                failed_table.add_row([
                    item["absolute_line"],
                    item["relative_line"],
                    item["language"],
                    item["full_outcome"],
                    item["demo_outcome"],
                    error_msg
                ])

            print(failed_table)

            # æŒ‰è¯­è¨€åˆ†ç»„æ˜¾ç¤ºå¤±è´¥è¡Œå·
            print(f"\nğŸ“ å„è¯­è¨€å¤±è´¥è¡Œå·:")
            for language in sorted(language_stats.keys()):
                if language_stats[language]["failed_indices"]:
                    failed_indices = language_stats[language]["failed_indices"]
                    # æŒ‰ç»å¯¹è¡Œå·æ’åº
                    failed_indices_sorted = sorted(failed_indices, key=lambda x: x["absolute_line"])

                    print(f"   {language}:")
                    for idx_info in failed_indices_sorted:
                        abs_line = idx_info["absolute_line"]
                        rel_line = idx_info["relative_line"]
                        print(f"     æ–‡ä»¶è¡Œå·: {abs_line}, è¯­è¨€è¡Œå·: {rel_line} (--line {rel_line})")
        else:
            print(f"\nâœ… æ‰€æœ‰æ•°æ®éƒ½å¤„ç†æˆåŠŸï¼")

        print("\n" + "="*80)


def main():
    parser = argparse.ArgumentParser(description='ç»Ÿä¸€JSONLæ–‡ä»¶å¤„ç†å™¨ï¼ˆæ”¯æŒå…¨éƒ¨è¯­è¨€ï¼‰')
    parser.add_argument('-i', '--input_file', help='è¾“å…¥çš„JSONLæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-m', '--max-items', type=int, help='æœ€å¤§å¤„ç†æ•°é‡')
    parser.add_argument('-l', '--line', type=int, help='æŒ‡å®šå¤„ç†ç¬¬å‡ è¡Œæ•°æ®ï¼ˆä»1å¼€å§‹ï¼‰')
    parser.add_argument('--server_ip', help='æœåŠ¡å™¨IPåœ°å€', default='21.86.44.177')
    parser.add_argument('--server_port', type=int, help='æœåŠ¡å™¨ç«¯å£', default=8080)
    parser.add_argument('-d', '--debug', action='store_true', help='å¯ç”¨debugæ¨¡å¼')
    parser.add_argument('-c', '--concurrency', type=int, default=5, help='å¹¶å‘è¿›ç¨‹æ•°ï¼ˆé»˜è®¤5ï¼‰')
    parser.add_argument('--lang', help='æŒ‡å®šå¤„ç†çš„ç¼–ç¨‹è¯­è¨€ï¼Œåªå¤„ç†è¯¥è¯­è¨€çš„æ•°æ®')

    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input_file):
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
        return
    
    # éªŒè¯å¹¶å‘æ•°
    if args.concurrency < 1:
        logger.error("å¹¶å‘æ•°å¿…é¡»å¤§äº0")
        return
    if args.concurrency > 20:
        logger.warning("å¹¶å‘æ•°è¿‡é«˜å¯èƒ½å¯¹æœåŠ¡å™¨é€ æˆå‹åŠ›ï¼Œå»ºè®®ä¸è¶…è¿‡20")

    # åˆ›å»ºå¤„ç†å™¨
    processor = UnifiedProcessor(args.server_ip, args.server_port)

    # å¤„ç†æ–‡ä»¶
    results = processor.process_file(args.input_file, args.max_items, args.line, args.debug, args.concurrency, args.lang)

    # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
    if args.output:
        output_file = args.output
    else:
        # ä»è¾“å…¥æ–‡ä»¶åæå–è¯­è¨€ä¿¡æ¯ï¼Œç”Ÿæˆå¸¦è¯­è¨€å‰ç¼€çš„è¾“å‡ºæ–‡ä»¶å
        input_basename = os.path.basename(args.input_file)
        base_name = input_basename.replace('.jsonl', '')  # ä¾‹å¦‚ï¼štypescript.jsonl -> typescript

        # å¦‚æœæŒ‡å®šäº†è¯­è¨€è¿‡æ»¤ï¼Œåœ¨æ–‡ä»¶åä¸­ä½“ç°
        if args.lang:
            output_file = f"{base_name}_{args.lang}_results.jsonl"
        else:
            output_file = f"{base_name}_results.jsonl"

    # ä¿å­˜ç»“æœ
    if results:
        processor.save_results(results, output_file)
        
        # ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
        processor.print_detailed_statistics(results)
    else:
        logger.warning("æ²¡æœ‰å¤„ç†ä»»ä½•æ•°æ®")


if __name__ == "__main__":
    # æ‰§è¡Œä¸»å‡½æ•°
    main()